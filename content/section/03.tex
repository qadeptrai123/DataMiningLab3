\section{Thuật toán \textsc{Fast-Filtering}}

Đối với Fast-Sampling và Fast-Estimation, các tâm được tạo ra bằng cách tìm xấp xỉ tọa độ trong từng chiều không gian. Tuy nhiên, quy trình lấy mẫu này có thể làm phát sinh các sai số tích lũy, dẫn đến sự suy giảm chất lượng phân cụm tổng thể. Trong phần này, dựa trên các thuật toán Fast-Sampling và Fast-Estimation, tác giả đề xuất một thuật toán heuristic thực tiễn hơn mang tên Fast-Filtering nhằm bảo toàn tốt hơn chất lượng phân cụm trong khi vẫn duy trì được thời gian chạy hiệu quả.

Thuật toán đề xuất được trình bày trong Thuật toán~\ref{alg:fast_filter}, với ý tưởng chủ đạo là trực tiếp tìm kiếm các xấp xỉ tâm cho từng cụm dự đoán thay vì xấp xỉ từng chiều độc lập. Tại bước 2, một tập hợp các mẫu được rút ra một cách ngẫu nhiên và độc lập từ mỗi cụm dự đoán để đóng vai trò là các tâm ứng viên. Sau đó, trong các bước 3-4, các bộ ước lượng được xây dựng dựa trên những ý tưởng tương tự từ thuật toán Fast-Estimation. Dựa trên các bộ ước lượng này, tâm ứng viên có chi phí phân cụm tối thiểu được lựa chọn tại bước 5 để xác định các khoảng chứa $(1-\alpha)m_i$ điểm gần nhất. Cuối cùng, tại bước 7, các trọng tâm của các tập điểm đã xác định được chọn làm các tâm cuối cùng. Trong Phụ lục A.4, tác giả cung cấp phân tích lý thuyết cho thuật toán Fast-Filtering và chỉ ra rằng, với việc điều chỉnh số lượng lân cận gần nhất cùng kích thước mẫu $R_1$ và $R_2$, thuật toán này có thể đưa ra một nghiệm xấp xỉ $(1 + O(\sqrt{\alpha}))$.

\begin{algorithm}[H]
\caption{Fast-Filtering}
\label{alg:fast_filter}
\begin{algorithmic}[1]
\Require Bài toán $k$-means $(P, k, d)$, tập các phân vùng $(P_1, P_2, \dots, P_k)$ với tỷ lệ lỗi $\alpha$, các tham số $R_1 > 0, R_2 > 0$ và $0 < \epsilon < 1$.
\Ensure Một tập $C \subset \mathbb{R}^d$ các tâm với $|C| \leq k$.
\For{$i = 1 .. k$}
\State Lấy mẫu ngẫu nhiên và độc lập một tập $U_i$ từ $P_i$ với kích thước $R_1$.
\State Lấy mẫu ngẫu nhiên và độc lập một tập $S_i$ từ $P_i$ với kích thước $R_2$, và gán cho mỗi điểm trong $S_i$ một trọng số $\frac{m_i}{|S_i|}$.
\State Xây dựng bộ ước lượng $\omega$ sao cho $\forall u \in U_i, \omega(u) = \sum_{p \in S_i \setminus F(u)} \frac{m_i}{|S_i|} \delta^2(p, u)$, trong đó $F(u)$ là tập hợp $(1+\epsilon)\alpha|S_i|$ điểm trong $S_i$ có khoảng cách xa nhất đối với $u$.
\State $c_i = \arg \min_{u \in U_i} \omega(u)$.
\State Gọi $I_i$ là tập hợp $(1-\alpha)m_i$ điểm trong $P_i$ gần $c_i$ nhất.
\State $\hat{c}_i = \bar{I}_i$.
\EndFor

\Return $\{\hat{c}_1, \hat{c}_2, \dots, \hat{c}_k\}$.
\end{algorithmic}
\end{algorithm}

\textbf{Giải thích thuật toán:}


\hl{
Thuật toán này giải quyết vấn đề ``sai số tích lũy''  bằng cách làm trực tiếp trên vecto thay vì gộp kết quả từ $d$ bài toán đơn chiều.
}
\begin{itemize}
    \item \textbf{Lấy mẫu $U_i$:} \hl{Ý tưởng giống Fast-Sampling \ref{alg:fast_sampling}, để tìm các ứng viên mà có quả cầu có tâm tại nó chứa tâm tối ưu.}

    \item \textbf{Ước lượng nhanh:} \hl{Ý tưởng giống Fast-Estimation \ref{alg:fast_estimation}. Tại bước 4, thay vì tính toán tổng bình phương khoảng cách $\delta^2$ trên toàn bộ tập dữ liệu $P_i$ (vốn tốn thời gian $O(m_i d)$), tác giả sử dụng tập mẫu $S_i$ có kích thước $R_2$ nhỏ hơn nhiều. Trọng số $\frac{m_i}{|S_i|}$ đảm bảo rằng kỳ vọng của bộ ước lượng $\omega(u)$ sẽ hội tụ về giá trị chi phí thực tế của cụm.}
    
    \item \textbf{Loại bỏ nhiễu:} \hl{Ý tưởng hay của tác giả là tập $F(u)$ gồm các điểm xa nhất. Trong bài toán có hỗ trợ học, cụm dự đoán $P_i$ có thể chứa tới $\alpha m_i$ điểm âm tính giả (nhiễu).}
\end{itemize}

% T 3
\begin{theorem}
\label{thm:fast_filtering_correctness}
Cho $R_1 = O\left( \frac{\log k}{1 - 2\alpha} \right)$ và $R_2 = O\left( \frac{\log(m^3d \log^3(m\Delta^2)/\epsilon^2) \log(m\Delta^2)}{\alpha \epsilon^4} \right)$, trong đó $\Delta$ là tỷ lệ chiều của tập dữ liệu. Với xác suất hằng số, Thuật toán 4 (Fast-Filtering) trả về nghiệm xấp xỉ $(1 + O(\sqrt{\alpha}))$ cho bài toán k-means có hỗ trợ học trong thời gian $O(md) + \tilde{O}\left( \frac{kd}{\epsilon^4(1-2\alpha)\alpha} \right)$ với $\alpha \in (0, 1/3 - \epsilon)$.
\end{theorem}



% C 3

\begin{corollary}
Cho kích thước mẫu $R_1 = \Theta\left( \frac{\log k}{1 - 2\alpha} \right)$. Với mỗi cụm dự đoán $i \in [k]$, với xác suất hằng số, tồn tại ít nhất một điểm dữ liệu $u$ trong tập mẫu $U_i$ sao cho $u \in G_2(P^*_i)$, trong đó $G_2(P^*_i)$ là tập hợp các điểm nằm gần tâm tối ưu.
\end{corollary}



% C 4

\begin{corollary}
\label{cor:estimator_bounds}
Cho 
\[ R_2 = O\left( \frac{\log(m^3d \log^3(m\Delta^2)/\epsilon_1^2) \log(m\Delta^2)}{\alpha\epsilon_1^4} \right) \]
Với một điểm dữ liệu bất kỳ $u \in U_i$, với xác suất cao, bộ ước lượng $\omega(u)$ thỏa mãn:
\[ \frac{\delta^2(P_i \setminus \mathcal{Z}^\dagger(u), u)}{1 + 7\epsilon_1} \leq \omega(u) \leq (1 + \epsilon_1)^2 \delta^2(H_i(u), u) \]
trong đó $H_i(u)$ là tập hợp $(1-\alpha)m_i$ điểm gần $u$ nhất trong $P_i$, và $\mathcal{Z}^\dagger(u)$ là tập hợp $(2 + 20\epsilon_1)\alpha m_i$ điểm xa $u$ nhất.
\end{corollary}



% L 12
\begin{lemma}
\label{lemma:distance_bound_fast_filtering}
Khoảng cách giữa trọng tâm của tập hợp đã lọc $\overline{I_i}$ và tâm tối ưu $c^*_i$ bị chặn như sau:
\[ \delta^2(\overline{I_i}, c^*_i) \leq \frac{9\delta^2(P^*_i, c^*_i)}{(1 - (3 + \epsilon)\alpha)m_i} \]
\end{lemma}



% Lemma 13 Improved

\begin{lemma}
\label{lemma:cost_bound_true_positives_explicit}
Chi phí phân cụm của tập $Q_i$ đối với tâm của tập hợp đã lọc $\overline{I_i}$ thỏa mãn chặn cụ thể sau:
\[ \delta^2(Q_i, \overline{I_i}) \leq \delta^2(Q_i, c^*_i) + \left( 5\sqrt{\alpha} + \frac{36(\sqrt{\alpha} + \alpha)}{1-(3+\epsilon)\alpha} \right) \delta^2(P^*_i, c^*_i) \]
\end{lemma}




% L 14

\begin{lemma}
\label{lemma:14}
Tổng chi phí phân cụm của cụm tối ưu $P^*_i$ đối với trọng tâm $\overline{I_i}$ bị chặn bởi:
\[ \delta^2(P^*_i, \overline{I_i}) \leq \left( 1 + 6\sqrt{\alpha} + \frac{36(\sqrt{\alpha} + \alpha)}{1-(3+\epsilon)\alpha} + \frac{9(\sqrt{\alpha}+\alpha)}{(1-\alpha)(1-(3+\epsilon)\alpha)} \right) \delta^2(P^*_i, c^*_i) \]
\end{lemma}
