\section{Kiến thức cơ sở}

Gọi $P \subset \mathbb{R}^d$ và $k$ lần lượt là tập dữ liệu và số lượng cụm. Gọi $m$ là kích thước của tập dữ liệu. Đối với hai điểm $p, q \in \mathbb{R}^d$ bất kỳ, ký hiệu $\delta(p, q)$ và $\delta^2(p, q)$ lần lượt là khoảng cách và bình phương khoảng cách giữa chúng. Cho một điểm $p \in \mathbb{R}^d$ và một tập các tâm $C = \{c_1, c_2, \dots, c_k\}$, gọi $\delta(p, C) = \min_{c \in C} \delta(p, c)$ là khoảng cách từ $p$ đến tâm gần nhất trong $C$. 

% BEGIN PB
\hl{Để ý có thể có nhiều cách phân cụm tối ưu nhưng ở đây tác giả chọn 1 cách cố định để phân tích.}
% END PB

Gọi $C^* = \{c^*_1, \dots, c^*_k\}$ và $\mathcal{P}(C^*) = \{P^*_1, \dots, P^*_k\}$ là tập các tâm tối ưu và phân hoạch phân cụm tối ưu tương ứng. Mỗi tâm tối ưu $c^*_i \in C^*$ được biểu diễn bởi $d$ tọa độ, tức là $c^*_i = (c^*_{i1}, c^*_{i2}, \dots, c^*_{id})$. Chi phí phân cụm của tập $P$ đối với tập tâm $C$ được định nghĩa là:
\begin{equation}
    \label{eq:cost_kmeans}
    \delta^2(P, C) = \sum_{x \in P} \delta^2(x, C)
\end{equation}

% BEGIN PB
\hl{
Nếu $P$ là 1 điểm (thay vì 1 tập hợp) thì công thức trên được dùng. Lưu ý ta quan tâm thứ tự trong toán tử $\delta^2$, viết cụm trước và tâm sau.
}
% END PB

Cho một tập hợp $\mathcal{L}(P) = \{P_1, P_2, \dots, P_k\}$ đóng vai trò là bộ dự đoán, gọi $Q_i = P_i \cap P^*_i$ là tập các điểm dữ liệu trong cụm dự đoán $P_i$ thuộc cụm tối ưu $P^*_i$. Gọi tọa độ chiếu của các điểm dữ liệu trong $P_i$ và $Q_i$ lên chiều thứ $j$ lần lượt là $P_{ij}$ và $Q_{ij}$. Gọi $P^*_{ij}$ là tọa độ chiếu của các điểm trong $P^*_i$ lên chiều thứ $j$. Gọi $m_i$ và $m$ lần lượt là kích thước của $P_i$ và $P$. Với một tập điểm dữ liệu $V \subset \mathbb{R}^d$, gọi $\overline{V}$ là trọng tâm \hl{(trung bình của các điểm)} của tập $V$. Gọi $P(j)$ là tọa độ chiếu của toàn bộ các điểm trong $P$ lên chiều thứ $j$. Gọi $\Delta_{max}$ là tỷ lệ chiều tối đa của các điểm dữ liệu được chiếu, được xác định bởi:
\begin{equation}
    \Delta_{max} = \max_{1 \leq j \leq d} \frac{\max_{x,y \in P(j)} \delta(x,y)}{\min_{x,y \in P(j), x \neq y} \delta(x,y)}
\end{equation}

% BEGIN PB
\hl{Cụm từ ``Aspect Ratio'' được tác giả đề cập khi dịch về tiếng Việt để
quen thuộc nhất thì chúng em sẽ gọi là \textbf{tỷ lệ khung hình}. Về bản chất thì cũng chỉ là tỉ lệ giữa khoảng cách lớn nhất của 2 điểm và khoảng cách nhỏ nhất của 2 điểm.}
% END PB

Với một số nguyên dương $t$, gọi $[t]$ là tập hợp các số nguyên từ 1 đến $t$.

\textbf{Bài toán $k$-means hỗ trợ học:} Cho tập dữ liệu $P \subset \mathbb{R}^d$ gồm $m$ điểm, gọi $C^*$ và $P(C^*) = \{P^*_1, P^*_2, \dots, P^*_k\}$ lần lượt là một lời giải tối ưu và phân hoạch tương ứng. Trong thiết lập có hỗ trợ học, giả định rằng có quyền truy cập vào một bộ dự đoán dưới dạng phân hoạch nhãn $L(P) = \{P_1, P_2, \dots, P_k\}$ được tham số hóa bởi tỷ lệ lỗi nhãn $\alpha \in [0, 1)$, thỏa mãn điều kiện $|P_i \cap P^*_i| \geq (1-\alpha) \max\{|P_i|, |P^*_i|\}$. Mục tiêu của bài toán là tìm tập $C \subset \mathbb{R}^d$ các tâm sao cho $\delta^2(P, C)$ đạt giá trị nhỏ nhất.

\hl{Cụm từ ``Learning-Augmented'' chúng em xin được phép dịch là \textbf{hỗ trợ học} để tránh gây hiểu lầm với cụm từ \textbf{học tăng cường}.}

% BEGIN PB
\hl{
Giống với chi phí tối ưu của bài toán $k$-means, chi phí suy ra từ \ref{eq:cost_kmeans}
}

\begin{align*}
    \delta^2(P, C) &= \sum_{i=1}^k \sum_{x \in P_i^*} \delta^2(x, c_i^*) \\
    &= \sum_{i=1}^k \sum_{x \in P_i^*} \delta^2(x, \overline{P_i^*})
\end{align*}

\hl{Trong không gian Euclid, trọng tâm $\overline{V}$ là điểm duy nhất tối thiểu hóa tổng bình phương khoảng cách tới mọi điểm trong tập $V$. Các bổ đề dưới đây cho phép phân rã chi phí phân cụm thành hai thành phần: chi phí trong cụm (độ liên kết - cohesion) và chi phí do khoảng cách từ tâm dự đoán đến tâm tối ưu.}
% END PB

Các bổ đề dưới đây là "dân gian truyền miệng" (folklore) rất phổ biến liên quan bài toán $k$-means clustering

\begin{lemma}
\label{lemma:1}
Cho tập $X \subset \mathbb{R}^d$ có kích thước $m$ và một điểm dữ liệu bất kỳ $c \in \mathbb{R}^d$, ta luôn có:
\begin{equation}
    \delta^2(X, c) = \delta^2(X, \overline{X}) + m \cdot \delta^2(c, \overline{X})
\end{equation}
\cite{Arthur2007}
\end{lemma}

% BEGIN PB
\hl{Bổ đề \ref{lemma:1} xuất phát từ quan sát trọng tâm $\overline{P_i}$ của các cụm dự đoán không đủ là nghiệm của bài toán. Vì dự đoán không đúng, có thể tồn tại 1 số điểm trong $P_i$ nằm ngoài $P_i^*$. Nếu các điểm trong $P_i \setminus P_i^*$ nằm \textbf{rất xa} $\overline{P_i^*}$, trọng tâm cụm dự đoán sẽ bị lệch tuỳ ý dẫn đến chi phí tăng cụm tăng lên tuỳ ý.} 

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1.5, >=Stealth]
        % 1. Định nghĩa màu sắc
        \definecolor{pointblue}{RGB}{31, 119, 180}
        \definecolor{centroidred}{RGB}{214, 39, 40}
        \definecolor{anypointorange}{RGB}{255, 127, 14}

        % 2. Tọa độ trọng tâm (Điểm đỏ)
        \coordinate (Xbar) at (-1.2, 1.0);
        
        % 3. Vẽ đám mây điểm X (Tỏa ra xa điểm đỏ để tránh chồng lấn)
        % Các tọa độ này được chọn để bao quanh Xbar nhưng có khoảng cách rõ ràng
        \foreach \pos in {(-2.0,1.5), (-0.6,1.4), (-1.9,0.4), (-0.7,0.3), (-2.2,0.9), (-0.4,0.8)} {
            \fill[pointblue!60] \pos circle (2pt);
            \draw[dashed, gray!30, thin] \pos -- (Xbar);
        }
        % Nhãn cho tập X
        \node[pointblue, font=\boldmath] at (-2.3, 1.7) {$X$};

        % 4. Vẽ trọng tâm X_bar (Điểm đỏ)
        \fill[centroidred] (Xbar) circle (2.8pt);
        % Nhãn X_bar được dịch chuyển xuống dưới một chút để không bị che khuất
        \node[centroidred, below left=2pt] at (Xbar) {\large $\overline{X}$};

        % 5. Điểm c bất kỳ (Điểm cam)
        \coordinate (C) at (1.8, 0.6);
        \fill[anypointorange] (C) circle (3pt);
        \node[anypointorange, right=3pt] at (C) {\large $c$};

        % 6. Đường nối và khoảng cách delta(c, X_bar)
        \draw[line width=1.5pt, anypointorange, <->] (Xbar) -- (C) 
            node[midway, above=2pt, black, font=\small] {$\delta(c, \overline{X})$};

        % 7.  một đường từ điểm xanh đến c (để thấy delta(X, c))
        \draw[dotted, thick, pointblue!80] (-0.4,0.8) -- (C);

    \end{tikzpicture}
    \caption{Khoảng cách từ các điểm $X$ đến $c$ liên hệ qua trọng tâm $\overline{X}$.}
\end{figure}


% END PB

\begin{lemma}
\label{lemma:2}
Cho tập $J \subset \mathbb{R}$, gọi $J_1 \subseteq J$ với $|J_1| \geq (1-\zeta)|J|$, trong đó $0 \leq \zeta < 1$. Khi đó, mối liên hệ giữa chi phí của tập con và tập tổng thể được chặn bởi:
\begin{equation}
    \delta^2(\overline{J}, \overline{J_1}) \leq \frac{\zeta}{(1-\zeta)|J|} \delta^2(J, \overline{J})
\end{equation}
\cite{Nguyen2022}
\end{lemma}

% BEGIN PB
\hl{Bổ đề \ref{lemma:2} cũng đúng với $J \subset \mathbb{R}^d$, mặc dù tác giả chỉ ghi trên $\mathbb{R}$, chứng minh tương tự như trong bài báo của} \cite{Nguyen2022} \hl{(phần chứng minh Bổ đề 3 trong mục Appendix 5.1).}

\definecolor{wewdxt}{rgb}{0.43, 0.43, 0.45} % Grey for lines
\definecolor{rvwvcq}{rgb}{0.08, 0.40, 0.75} % Blue for points
\begin{figure}[htbp]
    \centering
    % Định nghĩa màu sắc
    \definecolor{wewdxt}{rgb}{0.43, 0.43, 0.45}
    \definecolor{rvwvcq}{rgb}{0.08, 0.40, 0.75}

    \begin{tikzpicture}[line cap=round, line join=round, >=triangle 45, x=1.2cm, y=1.2cm]
        % Mở rộng vùng cắt để không bị mất hình bên trái
        \clip(-6.0, 0.0) rectangle (1.5, 6.5);

        % Vẽ các vòng tròn đại diện cho tập J và J1
        \draw [line width=1.2pt, color=wewdxt] (-2.61, 2.96) circle (2.738cm); % Tập J
        \draw [line width=1.2pt, color=wewdxt] (-1.83, 3.44) circle (1.387cm); % Tập J1
        
        % Đường nối giữa hai tâm (thể hiện khoảng cách delta)
        \draw [line width=1.5pt, color=rvwvcq] (-1.83, 3.44) -- (-2.61, 2.96);

    % 2. POINTS AND LABELS: 
    % We place the node inside the drawing command for the point so it stays attached.
    \begin{scriptsize}
        % Point J
        \fill [color=rvwvcq] (-2.61, 2.96) circle (2.5pt) node[below left, color=rvwvcq] {$\overline{J}$};

        % Point J1
        \fill [color=rvwvcq] (-1.83, 3.44) circle (2.5pt) node[above right, color=rvwvcq] {$\overline{J_1}$};
        
    \end{scriptsize}
\end{tikzpicture}
\caption{\hl{Bổ đề \ref{lemma:2} trong không gian $\mathbb{R}^d$: Khoảng cách giữa tâm tập tổng thể $\overline{J}$ và tâm tập con $\overline{J_1}$ được chặn bởi hàm chi phí của $J$.}}
\end{figure}

\hl{Bổ đề \ref{lemma:2} xuất phát từ quan sát liên hệ chi phí và kích thước tập con của cụm tối ưu. Ta muốn tìm $Q_i = P_i \cap P_i^*$ và lấy $\overline{Q_i}$ làm đáp án cho cụm $i$, điều này tự nhiên xuất phát từ dữ kiện $Q_i$ của bài toán có hỗ trợ học.} 
\begin{align*}
|Q_i| &\geq (1-\alpha) \max\{|P_i|, |P^*_i|\} \geq (1 - \alpha) |P_i^*| \\
\Rightarrow |P_i^* \setminus Q_i| &\leq \alpha m_i^*
\end{align*}

\hl{Dùng bổ đề trên, ta có chặn trên chi phí phân cụm:} 
\begin{align*}
\delta^2(P_i^*, \overline{Q_i}) &=\delta^2(P_i^*, \overline{P_i^*}) +  m_i^* \delta^2(\overline{P_i^*}, \overline{Q_i}) \quad &\text{   (Bổ đề \ref{lemma:1})} \\
 &\leq \delta^2(P_i^*, \overline{P_i^*}) + m_i^* \frac{\alpha}{1 - \alpha}  \frac{\delta^2(P_i^*, \overline{P_i^*})}{m_i^*} \quad &\text{    (Bổ đề \ref{lemma:2})}\\
 &= \left(1 + \frac{\alpha}{1 - \alpha} \right) \delta^2(P_i^*, \overline{P_i^*})
\end{align*}

\hl{Như vậy ta có xấp xỉ $\left(1 + \frac{\alpha}{1 - \alpha} \right)$ cho 1 cụm và cũng như cho bài toán. Cũng chính là chặn dưới và lí do xuất hiện của nó trong tỷ lệ xấp xỉ trong Bảng \ref{tab:theoretical_comparison}.}

\hl{Khó khăn là $Q_i$ chưa biết, vì vậy các thuật toán chính dưới đây tập trung vào việc loại bỏ các điểm outlier trong $P_i$, tìm một trọng tâm gần $\overline{Q_i}$, như vậy đồng thời giảm được khoảng cách đến $\overline{P_i^*}$ và chi phí.} 
% END PB


\begin{lemma}
\label{lemma:3}
Cho tập $X \subset \mathbb{R}^d$ và một giá trị $\alpha \in (0, 1]$, gọi $X' = \arg \min_{X'' \subseteq X, |X''| = \alpha|X|} \delta^2(X'', \overline{X''})$. Khi đó, ta có:
\begin{equation}
    \delta^2(X', \overline{X'}) \leq \alpha \cdot \delta^2(X, \overline{X})
\end{equation}
\cite{Nguyen2022}
\end{lemma}

Kết quả của Bổ đề \ref{lemma:3} được chứng minh bằng phương pháp xác suất (probabilistic method), xem chi tiết tại phần đầu trong chứng minh của Bổ đề 5 (Appendix 5.1) trong bài báo của \cite{Nguyen2022}.

% BEGIN PB
\subsection{Các công cụ (toán)}

% Relaxed triangle ineq
\begin{theorem2}[Bất đẳng thức tam giác nới lỏng - relaxed triangle inequality]
\label{thm:relaxed_triangle}
Với mọi số thực $a, b \in \mathbb{R}$ và một tham số dương $\lambda > 0$, bất đẳng thức sau luôn thỏa mãn:
\[ (a + b)^2 \leq \left(1 + \frac{1}{\lambda}\right)a^2 + (1 + \lambda)b^2 \]
Trong không gian vector $\mathbb{R}^d$ với chuẩn Euclid $\| \cdot \|$, bất đẳng thức này tương đương với:
\[ \|u + v\|^2 \leq \left(1 + \frac{1}{\lambda}\right)\|u\|^2 + (1 + \lambda)\|v\|^2 \]
\end{theorem2}

\begin{proof}
\hl{Ở đây nhóm em chứng minh cho 1 chiều, còn lại cũng tương tự. Ta bắt đầu bằng việc khai triển vế trái của bất đẳng thức:}
\[ (a + b)^2 = a^2 + 2ab + b^2 \]

\hl{Ta áp dụng bất đẳng thức AM-GM. Với hai số thực dương $x, y$, ta luôn có $x^2 + y^2 \geq 2xy$.}
\hl{Chọn $x = \frac{a}{\sqrt{\lambda}}$ và $y = b\sqrt{\lambda}$. Khi đó:}
\[ \left( \frac{a}{\sqrt{\lambda}} \right)^2 + (b\sqrt{\lambda})^2 \geq 2 \left( \frac{a}{\sqrt{\lambda}} \right) (b\sqrt{\lambda}) \]

\[ \frac{a^2}{\lambda} + \lambda b^2 \geq 2ab \]

\hl{Thay thế chặn trên của $2ab$ vào khai triển ban đầu của $(a + b)^2$:}
\begin{align*}
    (a + b)^2 &= a^2 + 2ab + b^2 \\
    &\leq a^2 + \left( \frac{a^2}{\lambda} + \lambda b^2 \right) + b^2 \\
    &= \left( a^2 + \frac{a^2}{\lambda} \right) + (b^2 + \lambda b^2) \\
    &= \left( 1 + \frac{1}{\lambda} \right)a^2 + (1 + \lambda)b^2
\end{align*}

\end{proof}
% END PB

% Union bound
\begin{theorem2}[Chặn hợp - Bất đẳng thức Boole]
\label{thm:union_bound}
Nếu $A_1, A_2, \dots, A_n$  là các sự kiện thì xác suất để ít nhất một sự kiện xảy ra nhỏ hơn tổng xác suất của tất cả các sự kiện.
\[ \Pr\left(\bigcup_{i=1}^{n} A_i\right) \leq \sum_{i=1}^{n} \Pr(A_i) \]
\end{theorem2}

% BEGIN PB
\hl{Định lý \ref{thm:union_bound} khá tự nhiên và dễ thấy. Xét ví dụ với hai sự kiện $A$ và $B$. Xác suất để ít nhất một trong hai sự kiện xảy ra là xác suất của hợp $A \cup B$. Ta có thể biểu diễn mối quan hệ này trên biểu đồ Venn như Hình \ref{fig:union_bound}.}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[line cap=round, line join=round, >=triangle 45, x=1cm, y=1cm]
        \def\firstcircle{(-1.2,0) circle (1.8cm)}
        \def\secondcircle{(1.2,0) circle (1.8cm)}
        
        % Fill intersection
        \begin{scope}
            \clip \firstcircle;
            \fill[color=rvwvcq, fill opacity=0.1] \secondcircle;
        \end{scope}
        
        \draw [line width=1.5pt, color=wewdxt] \firstcircle;
        \draw [line width=1.5pt, color=wewdxt] \secondcircle;
        
        \node [color=rvwvcq] at (-1.8, 0) {\Large $A$};
        \node [color=rvwvcq] at (1.8, 0) {\Large $B$};
        \node [color=rvwvcq] at (0, 0) {\footnotesize $A \cap B$};
    \end{tikzpicture}
    \caption{\hl{Minh họa chặn hợp với hai sự kiện $A$ và $B$. Phần giao $A \cap B$ (được tô màu) được tính hai lần trong tổng $\Pr(A) + \Pr(B)$.}}
    \label{fig:union_bound}
\end{figure}

\hl{Từ hình \ref{fig:union_bound}, ta thấy diện tích của phần hợp $A \cup B$ bằng tổng diện tích của $A$ và $B$ trừ đi diện tích phần giao nhau $A \cap B$ (vì phần này được tính hai lần trong tổng). Chuyển sang công thức xác suất:}
\[ \Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B) \]
\hl{Vì xác suất của phần giao luôn không âm ($\Pr(A \cap B) \geq 0$), ta suy ra bất đẳng thức:}
\[ \Pr(A \cup B) \leq \Pr(A) + \Pr(B) \]
\hl{Mở rộng tương tự cho $n$ sự kiện, ta có định lý chặn hợp (union bound).}

\hl{Trong bài báo, tác giả dùng định lý \ref{thm:union_bound} để gộp xác suất thất bại trên từng chiều dữ liệu ($d$) và trên từng cụm ($k$), đảm bảo rằng thuật toán Fast-Sampling vẫn đúng trên toàn bộ không gian dữ liệu.}
% END PB

% Chernoff bound
\begin{theorem2}[Chặn Chernoff]
\label{thm:chernoff}
Cho $X_1, X_2, \dots, X_n$ là các biến ngẫu nhiên độc lập nhận giá trị trong khoảng $[0, 1]$. Gọi $X = \sum_{i=1}^n X_i$ và $\mu = \mathbb{E}[X]$.
\begin{enumerate}
    \item Với mọi $\delta > 0$, ta có:
    \[ \Pr(X \geq (1+\delta)\mu) \leq \exp\left(-\frac{\delta^2 \mu}{2+\delta}\right) \]
    \item Với mọi $0 < \delta < 1$, ta có:
    \[ \Pr(X \leq (1-\delta)\mu) \leq \exp\left(-\frac{\delta^2 \mu}{2}\right) \]
\end{enumerate}
\end{theorem2}

% BEGIN PB
\hl{Trong bối cảnh của bài báo này (và các thuật toán ngẫu nhiên nói chung), chặn Chernoff cực kỳ quan trọng để chứng minh tính hiệu quả của phương pháp lấy mẫu (sampling).} 
\hl{Cụ thể, các thuật toán được đề xuất (như Fast-Sampling) không duyệt qua toàn bộ dữ liệu mà chỉ lấy một tập mẫu ngẫu nhiên $S$. Chúng ta cần đảm bảo rằng các đặc tính của mẫu $S$ (ví dụ: tỷ lệ các điểm thuộc cụm tối ưu) xấp xỉ tốt các đặc tính của tập dữ liệu gốc $P$.}
\hl{Chặn Chernoff cho ta biết xác suất để giá trị thực nghiệm lệch khỏi giá trị kỳ vọng sẽ giảm theo hàm mũ. Điều này đảm bảo rằng chỉ cần kích thước mẫu $O(\log m)$, ta có thể đạt được độ chính xác mong muốn với xác suất rất cao (\textit{high probability}).}
% END PB

% Cauchy Schwarz
\begin{theorem2}[Bất đẳng thức Cauchy-Schwarz]
\label{thm:cauchy_schwarz}
Với mọi $u, v$ thuộc không gian tích vô hướng thực, ta có:
\[ |\langle u, v \rangle|^2 \leq \langle u, u \rangle \cdot \langle v, v \rangle \]
Hay viết dưới dạng chuẩn (norm) trong không gian Euclid $\mathbb{R}^d$:
\[ |\langle u, v \rangle| \leq \|u\| \cdot \|v\| \]
Dấu đẳng thức xảy ra khi và chỉ khi $u$ và $v$ phụ thuộc tuyến tính (cùng phương).
\end{theorem2}

% BEGIN PB
\hl{Bất đẳng thức này thường xuyên được sử dụng trong các chứng minh liên quan đến $k$-means để tách và đánh giá các thành phần của hàm chi phí.}
\hl{Ví dụ, khi khai triển $\delta^2(x, c) = \|x - c\|^2 = \|(x - c^*) + (c^* - c)\|^2$, ta sẽ gặp số hạng chéo $2\langle x - c^*, c^* - c \rangle$. Cauchy-Schwarz giúp chặn trên giá trị tuyệt đối của số hạng này, từ đó giúp thiết lập các mối quan hệ giữa chi phí của lời giải xấp xỉ và lời giải tối ưu.}
% END PB

\subsection{Các thuật toán con}

\subsubsection{Chọn phần tử hạng thứ $i$ trong dãy}

Trong các thuật toán được đề xuất, có nhiều bước yêu cầu tìm một giá trị ngưỡng để lọc bớt dữ liệu hoặc xác định khoảng cách (ví dụ: tìm bán kính bao phủ một tỷ lệ nhất định các điểm).
Nếu sử dụng thuật toán sắp xếp (Sorting) thông thường (như QuickSort, MergeSort), độ phức tạp sẽ là $O(m \log m)$. Tuy nhiên, để đạt được mục tiêu thiết kế thuật toán chạy trong thời gian tuyến tính $O(m)$, ta cần sử dụng thuật toán chọn lọc (selection algorithm), cụ thể là thuật toán \textbf{Median of Medians} (gốc là thuật toán \textbf{PICK} trong bài báo \cite{Blum1973}).

\textbf{Bài toán:} Cho một tập hợp $S$ gồm $n$ phần tử chưa được sắp xếp và một số nguyên $i$ ($1 \leq i \leq n$). Hãy tìm phần tử nhỏ thứ $i$ trong $S$.

\textbf{Mô tả thuật toán:}

\begin{enumerate}
    \item \textbf{Chia nhóm:} Chia $n$ phần tử của $S$ thành các nhóm có 5 phần tử (nhóm cuối cùng có thể ít hơn 5 phần tử).
    
    \item \textbf{Tìm trung vị con:} Với mỗi nhóm, tìm trung vị của nó (bằng cách sắp xếp cục bộ). Tập hợp các trung vị này được gọi là $T$ (kích thước $\approx n/5$).
    
    \item \textbf{Tìm chốt (pivot):} Gọi đệ quy thuật toán này để tìm trung vị của tập $T$. Gọi giá trị tìm được là $m$ (đây chính là "trung vị của các trung vị").
    
    \item \textbf{Phân hoạch:} Chia tập $S$ ban đầu thành 3 tập con dựa trên chốt $m$:
    \begin{itemize}
        \item $L = \{x \in S \mid x < m\}$ (Các phần tử nhỏ hơn $m$).
        \item $E = \{x \in S \mid x = m\}$ (Các phần tử bằng $m$).
        \item $G = \{x \in S \mid x > m\}$ (Các phần tử lớn hơn $m$).
    \end{itemize}
    
    \item \textbf{Chọn lọc đệ quy:}
    \begin{itemize}
        \item Nếu $k \leq |L|$: Kết quả nằm trong $L$. Gọi đệ quy tìm phần tử thứ $k$ trong $L$.
        \item Nếu $|L| < k \leq |L| + |E|$: Trả về $m$.
        \item Nếu $k > |L| + |E|$: Kết quả nằm trong $G$. Gọi đệ quy tìm phần tử thứ $(k - |L| - |E|)$ trong $G$.
    \end{itemize}
\end{enumerate}


% BEGIN PB
\hl{\textbf{Giải thích một chút về độ phức tạp:}}
\hl{Trong bài báo gốc của} \cite{Blum1973}\hl{, tác giả chứng minh rằng thuật toán Median of Medians chạy trong thời gian $O(n)$ trong trường hợp xấu nhất.}
\hl{Thuật toán khắc phục vấn đề chọn chốt (pivot) ngẫu nhiên của QuickSelect bằng cách tốn một chút chi phí để chọn ra một chốt $m$ ``đủ tốt'' ~(nằm gần giữa dãy số).}
\begin{itemize}
    \item \hl{Vì $m$ là trung vị của các trung vị, nó lớn hơn trung vị của một nửa số nhóm.}
    \item \hl{Trong mỗi nhóm đó, trung vị lại lớn hơn 2 phần tử khác.}
    \item \hl{Suy ra: $m$ chắc chắn lớn hơn khoảng $30\%$ số phần tử của $S$. Tương tự, $m$ chắc chắn nhỏ hơn khoảng $30\%$ số phần tử.}
    \item \hl{Do đó, ở bước phân hoạch, ta luôn loại bỏ được ít nhất $30\%$ dữ liệu. Kích thước bài toán giảm xuống rất nhanh theo cấp số nhân, đảm bảo tổng thời gian là tuyến tính.}
\end{itemize}


\hl{\textbf{Ý nghĩa:}}
\hl{Trong các thuật toán đề xuất (Fast-Sampling, Fast-Estimation), tác giả cần liên tục tìm tập hợp ``nearest neighbors'' ~(ví dụ: tìm $(1-\alpha)m_i$ điểm gần nhất). Việc sử dụng thuật toán này cho phép tìm ngưỡng khoảng cách trong $O(m)$ thay vì phải sắp xếp toàn bộ dữ liệu tốn $O(m \log m)$. Đây là chìa khóa để đạt được tốc độ xử lý nhanh trên dữ liệu lớn.}
% END PB